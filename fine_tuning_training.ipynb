{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakcroft/fine-tuning-notebooks/blob/main/fine_tuning_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmjAlA5T_XMO",
        "outputId": "f6e680b8-7d6a-42ff-b7ce-560709651742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/519.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/519.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m481.3/519.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting config\n",
            "  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lamini\n",
            "  Downloading lamini-0.0.21-3-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[torch])\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[torch])\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Collecting accelerate>=0.20.3 (from transformers[torch])\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.* (from lamini)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lamini-configuration[yaml] (from lamini)\n",
            "  Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n",
            "Collecting jsonlines (from lamini)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.*->lamini) (4.7.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, config, xxhash, pydantic, lamini-configuration, jsonlines, dill, responses, multiprocess, huggingface-hub, transformers, lamini, datasets, evaluate, accelerate\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.2.1\n",
            "    Uninstalling pydantic-2.2.1:\n",
            "      Successfully uninstalled pydantic-2.2.1\n",
            "Successfully installed accelerate-0.22.0 config-0.5.1 datasets-2.14.4 dill-0.3.7 evaluate-0.4.0 huggingface-hub-0.16.4 jsonlines-4.0.0 lamini-0.0.21 lamini-configuration-0.8.3 multiprocess-0.70.15 pydantic-1.10.12 responses-0.18.0 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets config transformers[torch] lamini evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOnf158m-DRu",
        "outputId": "015c47be-ff56-4150-afb1-fa5366daa690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/deeplearning_fine_tuning\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/deeplearning_fine_tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndBvkLEWzR1V"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "import config\n",
        "import os\n",
        "import yaml\n",
        "import logging\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# from utilities import *\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NchNUm5b9QDV",
        "outputId": "48b636a3-960b-4097-9c74-dd556f7100ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine_tuning_data_prepare.ipynb\tlamini_docs_3_steps  __pycache__\n",
            "fine_tuning_training.ipynb\tlamini_docs.jsonl    utilities.py\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc5ylTni4jcN",
        "outputId": "e9973bda-f228-4e4d-eaca-81d81b75fa94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select GPU device\n"
          ]
        }
      ],
      "source": [
        "device_count = torch.cuda.device_count()\n",
        "logger.debug(\"Checking device\")\n",
        "if device_count > 0:\n",
        "    print(\"Select GPU device\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"Select CPU device\")\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "8396707434b24879871760f51472da87",
            "1cafeea175b24b5380f9a9a05acf8ec6",
            "4461be39393d4b7f9f344e3f6ffe0957",
            "5c0976f59f6b47c9b8afc4adfd2cd4cd",
            "3ab990b1c78d458c882b46f962469e5a",
            "d5302d0a0df5455398d6390a7515a726",
            "77a585e2f3304e5db8fa7bcb4e81e4b1",
            "87108bb468f5458c815c68b9d0ccf5ed",
            "6518c1806e0f4946ade22f00688c1fb4",
            "a046aef3c2cb4f5499a0fa36abf9c06b",
            "fd3fcae751fa4df792d78028a8f05069",
            "acfa8d7d64ae43999d1e5c46135bbeef",
            "2eb94f0b8f254c7ea982a92efa709911",
            "ea1a4f4dcf12467f8ebb04530a8b037a",
            "cc1c54b32e484e598910ef92b0c1a0d2",
            "67300db2e1b24ea08d836c00c3147cb9",
            "03db0b6349ac4d52a84e8b65e87966d6",
            "076d0310d192460898c4ce380107136d",
            "01a88858d9504a8b954941b739609d62",
            "d5709c7680cb4c4ca40293e8895bd3bb",
            "d172e9c0c7154bc5b85deba861aa6fb5",
            "4c91971e853f4cdaa9a32de157f9564a",
            "2999b4c9d7b64e0c8c0b5645c0b65edf",
            "0dec15ee0dee4fbaa97d03106022ff78",
            "459dd1d481ac45fabf8cd24641a9aa81",
            "cb84c1fbaedc4d6ba7073548772bda43",
            "edc72ad4b89c47c3a12f801ebde2c57e",
            "9ea2b34533914213a955b588fcaf8c3b",
            "9604d5772f8b4b509f7849cc97ff6a7d",
            "86b0e049174649dc9797caf85199e764",
            "373601e821c340d1967433f13e881d3d",
            "93cf8fa8b694457a880b2a801f5ca730",
            "2270a337c10d43e68e8474ae198d23af",
            "f7c2257bb5244aa59c185995b681fb29",
            "6ea365bafb1f443994f001e1e89ca124",
            "820a90c9f897460eb8053dd05d8ed820",
            "57b6098b4c4946a9b02c704f29c06de8",
            "1f40aa921cc94bd9a19f7e63f8e33b5a",
            "e79ae5bb56694802b95eb0ddbb6a9342",
            "ccd9f2880cd3426fbb335580e14d2a54",
            "e3344b67b1c14feea012cc98d3be1d25",
            "e9251bfbc8db426195e26b70c3c108a7",
            "0420e67bb7cb4fbfb937170b28bd791c",
            "8f3c55a1e8cc4e869761d3230a89ea51",
            "a42bf169a3ef421682603ccc6794b97e",
            "16b73b28dfda49398095cab2b5794afe",
            "a13b3e6a3f13455798be5bdd6af6c766",
            "a9dd5881ecc24c58a7d316bb6544d5fc",
            "dbc0807d655e40dd9667b8c806fb9dcf",
            "74637a7a10e34026a8119aba50d7225e",
            "396fbd9552554f6abfb90577d64b30aa",
            "bb0ff6a104a64f619baa6a7671199d16",
            "2d7e33acd9f24710b8fa450d4c959493",
            "d30352474a6240878a177ba8fa2b1e98",
            "7c8abc075dde44699f021a638b3933eb"
          ]
        },
        "id": "rHoRqexlCrSs",
        "outputId": "1a929668-ef78-4b67-8570-ce9ea4e1e3e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8396707434b24879871760f51472da87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acfa8d7d64ae43999d1e5c46135bbeef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2999b4c9d7b64e0c8c0b5645c0b65edf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7c2257bb5244aa59c185995b681fb29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a42bf169a3ef421682603ccc6794b97e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"EleutherAI/pythia-70m\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "base_model.to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXLvx33v3seD",
        "outputId": "5e53c7c8-fb6b-4daf-dc88-2a97beb3cb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How can I evaluate the performance and quality of the generated text from Lamini models?\n",
            "There are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\n",
            "Can Lamini generate technical documentation or user manuals for software projects?\n",
            "Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"lamini/lamini_docs\"\n",
        "\n",
        "dataset = datasets.load_dataset(dataset_path)\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "\n",
        "print(train_dataset[0]['question'])\n",
        "print(train_dataset[0]['answer'])\n",
        "\n",
        "print(test_dataset[0]['question'])\n",
        "print(test_dataset[0]['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "8aa24fcfc8c74f529310a03da3657da2",
            "2272667e0eb046bdb7a6ce3e4d3d8fac",
            "21b4d41ac9ad448e9b50c9849ae9c4cc",
            "aa48d48a35454eae884e3dbb656b24c0",
            "558a8c151d4a47b0b466810e1c9c9ce0",
            "d7088d5e2cd74b75b331c8b3a7fab461",
            "29342cfcfd6a40f8b122ff64fa9a79c8",
            "3c9b2feec59643a69ba79497b2d221ff",
            "52aefb5457fc4cde80ef31d80432dfeb",
            "74fafdb1b92e4366930df63b194b77f9",
            "f32005b0328f4bd3b720fe093c9b15de"
          ]
        },
        "id": "lpJakYlADaSQ",
        "outputId": "a7689a76-6551-401a-90c0-defd67bd917a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'How can I evaluate the performance and quality of the generated text from Lamini models?', 'answer': \"There are several metrics that can be used to evaluate the performance and quality of generated text from Lamini models, including perplexity, BLEU score, and human evaluation. Perplexity measures how well the model predicts the next word in a sequence, while BLEU score measures the similarity between the generated text and a reference text. Human evaluation involves having human judges rate the quality of the generated text based on factors such as coherence, fluency, and relevance. It is recommended to use a combination of these metrics for a comprehensive evaluation of the model's performance.\", 'input_ids': [2347, 476, 309, 7472, 253, 3045, 285, 3290, 273, 253, 4561, 2505, 432, 418, 4988, 74, 3210, 32, 2512, 403, 2067, 17082, 326, 476, 320, 908, 281, 7472, 253, 3045, 285, 3290, 273, 4561, 2505, 432, 418, 4988, 74, 3210, 13, 1690, 44229, 414, 13, 378, 1843, 54, 4868, 13, 285, 1966, 7103, 15, 3545, 12813, 414, 5593, 849, 973, 253, 1566, 26295, 253, 1735, 3159, 275, 247, 3425, 13, 1223, 378, 1843, 54, 4868, 5593, 253, 14259, 875, 253, 4561, 2505, 285, 247, 3806, 2505, 15, 8801, 7103, 8687, 1907, 1966, 16006, 2281, 253, 3290, 273, 253, 4561, 2505, 1754, 327, 2616, 824, 347, 25253, 13, 2938, 1371, 13, 285, 17200, 15, 733, 310, 8521, 281, 897, 247, 5019, 273, 841, 17082, 323, 247, 11088, 7103, 273, 253, 1566, 434, 3045, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2347, 476, 309, 7472, 253, 3045, 285, 3290, 273, 253, 4561, 2505, 432, 418, 4988, 74, 3210, 32, 2512, 403, 2067, 17082, 326, 476, 320, 908, 281, 7472, 253, 3045, 285, 3290, 273, 4561, 2505, 432, 418, 4988, 74, 3210, 13, 1690, 44229, 414, 13, 378, 1843, 54, 4868, 13, 285, 1966, 7103, 15, 3545, 12813, 414, 5593, 849, 973, 253, 1566, 26295, 253, 1735, 3159, 275, 247, 3425, 13, 1223, 378, 1843, 54, 4868, 5593, 253, 14259, 875, 253, 4561, 2505, 285, 247, 3806, 2505, 15, 8801, 7103, 8687, 1907, 1966, 16006, 2281, 253, 3290, 273, 253, 4561, 2505, 1754, 327, 2616, 824, 347, 25253, 13, 2938, 1371, 13, 285, 17200, 15, 733, 310, 8521, 281, 897, 247, 5019, 273, 841, 17082, 323, 247, 11088, 7103, 273, 253, 1566, 434, 3045, 15]}\n",
            "{'question': 'Can Lamini generate technical documentation or user manuals for software projects?', 'answer': 'Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.', 'input_ids': [5804, 418, 4988, 74, 6635, 7681, 10097, 390, 2608, 11595, 84, 323, 3694, 6493, 32, 4374, 13, 418, 4988, 74, 476, 6635, 7681, 10097, 285, 2608, 11595, 84, 323, 3694, 6493, 15, 733, 4648, 3626, 3448, 5978, 5609, 281, 2794, 2590, 285, 44003, 10097, 326, 310, 3477, 281, 2096, 323, 1097, 7681, 285, 1327, 14, 48746, 4212, 15, 831, 476, 5321, 12259, 247, 1534, 2408, 273, 673, 285, 3434, 275, 6153, 10097, 13, 6941, 731, 281, 2770, 327, 643, 7794, 273, 616, 6493, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [5804, 418, 4988, 74, 6635, 7681, 10097, 390, 2608, 11595, 84, 323, 3694, 6493, 32, 4374, 13, 418, 4988, 74, 476, 6635, 7681, 10097, 285, 2608, 11595, 84, 323, 3694, 6493, 15, 733, 4648, 3626, 3448, 5978, 5609, 281, 2794, 2590, 285, 44003, 10097, 326, 310, 3477, 281, 2096, 323, 1097, 7681, 285, 1327, 14, 48746, 4212, 15, 831, 476, 5321, 12259, 247, 1534, 2408, 273, 673, 285, 3434, 275, 6153, 10097, 13, 6941, 731, 281, 2770, 327, 643, 7794, 273, 616, 6493, 15]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8aa24fcfc8c74f529310a03da3657da2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Can Lamini generate technical documentation or user manuals for software projects?\\n\\nI have a question about the following:\\n\\nHow do I get the correct documentation to work?\\n\\nA:\\n\\nI think you need to use the following code:\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use the following code to get the correct documentation.\\n\\nA:\\n\\nYou can use']\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"question\"], padding=True, truncation=True,  return_tensors=\"pt\", max_length=512)\n",
        "\n",
        "small_train_dataset = dataset[\"train\"].select(range(1))\n",
        "small_test_dataset = dataset[\"test\"].select(range(1))\n",
        "\n",
        "# print(train_dataset)\n",
        "print(small_train_dataset[0])\n",
        "print(small_test_dataset[0])\n",
        "\n",
        "# encode\n",
        "encoding_dataset = small_test_dataset.map(tokenize_function, batched=True)\n",
        "input_ids=torch.tensor(encoding_dataset['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(encoding_dataset['attention_mask']).to(device)\n",
        "\n",
        "# ask\n",
        "base_model_generated_tokens_with_prompt = base_model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=512\n",
        "  )\n",
        "\n",
        "# decode\n",
        "generated_text_with_prompt = tokenizer.batch_decode(base_model_generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "print(generated_text_with_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lryF_OreCxeB",
        "outputId": "ca5f1ce2-b1a0-41fe-cdbc-6917c7b87cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models answer: \n",
            "\n",
            "I have a question about the following:\n",
            "\n",
            "How do I get the correct documentation to work?\n",
            "\n",
            "A:\n",
            "\n",
            "I think you need to use the following code:\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use\n"
          ]
        }
      ],
      "source": [
        "# print(\"Question input:\", small_train_dataset[0]['question'])\n",
        "# print(\"Correct answer from Lamini docs:\", small_train_dataset[0]['answer'])\n",
        "\n",
        "# # Strip the prompt\n",
        "base_model_generated_answer = generated_text_with_prompt[0][len(small_test_dataset[0]['question']):].replace('.', '.\\n')\n",
        "\n",
        "print('Models answer:', base_model_generated_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixQNiai9TuGH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now train\n",
        "\n",
        "max_steps = -1\n",
        "epochs=2\n",
        "batch_size=1\n",
        "\n",
        "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
        "output_dir = trained_model_name\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "\n",
        "  # Learning rate\n",
        "  learning_rate=1.0e-5,\n",
        "\n",
        "  # Number of training epochs\n",
        "  num_train_epochs=epochs,\n",
        "\n",
        "  # Max steps to train for (each step is a batch of data)\n",
        "  # Overrides num_train_epochs, if not -1\n",
        "  max_steps=max_steps,\n",
        "\n",
        "  # Batch size for training\n",
        "  per_device_train_batch_size=batch_size,\n",
        "\n",
        "  # Directory to save model checkpoints\n",
        "  output_dir=output_dir,\n",
        "\n",
        "  # Other arguments\n",
        "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
        "  disable_tqdm=False, # Disable progress bars\n",
        "  eval_steps=120, # Number of update steps between two evaluations\n",
        "  save_steps=120, # After # steps model is saved\n",
        "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
        "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
        "  evaluation_strategy=\"steps\",\n",
        "  logging_strategy=\"steps\",\n",
        "  logging_steps=1,\n",
        "  optim=\"adafactor\",\n",
        "  gradient_accumulation_steps = 4,\n",
        "  gradient_checkpointing=False,\n",
        "\n",
        "  # Parameters for early stopping\n",
        "  load_best_model_at_end=True,\n",
        "  save_total_limit=1,\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False\n",
        ")\n",
        "\n",
        "model_flops = (\n",
        "  base_model.floating_point_ops(\n",
        "    {\n",
        "       \"input_ids\": torch.zeros(\n",
        "           (1, 2048)\n",
        "      )\n",
        "    }\n",
        "  )\n",
        "  * training_args.gradient_accumulation_steps\n",
        ")\n",
        "\n",
        "# print(base_model)\n",
        "# print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
        "# print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mDxK-b5Nj6F"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv870GZTLBkJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)  # Assumes `tokenizer` is previously defined\n",
        "\n",
        "\n",
        "class FilteredDataset(Dataset):\n",
        "    def __init__(self, original_dataset):\n",
        "        self.filtered_data = [item for item in original_dataset if len(item['input_ids']) > 0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.filtered_data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filtered_data)\n",
        "small_train_dataset = dataset[\"train\"].select(range(230))\n",
        "small_test_dataset = dataset[\"train\"].select(range(230))\n",
        "filtered_train_dataset = FilteredDataset(small_train_dataset)\n",
        "filtered_test_dataset = FilteredDataset(small_test_dataset)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=filtered_train_dataset,\n",
        "    eval_dataset=filtered_test_dataset,\n",
        "    data_collator=data_collator,  # Add this line\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "6yPO2hy1Qugl",
        "outputId": "9bd51cdf-ecb1-4b57-f34d-6f104b84db6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 00:15, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainOutput(global_step=114, training_loss=0.517733567639401, metrics={'train_runtime': 15.3871, 'train_samples_per_second': 29.895, 'train_steps_per_second': 7.409, 'total_flos': 9723173978112.0, 'train_loss': 0.517733567639401, 'epoch': 1.98})\n"
          ]
        }
      ],
      "source": [
        "training_output = trainer.train()\n",
        "\n",
        "print(training_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLZZY8MpVBId",
        "outputId": "05329e45-c8e5-404e-fce0-0d0921562a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: lamini_docs_-1_steps/final\n"
          ]
        }
      ],
      "source": [
        "save_dir = f'{output_dir}/final'\n",
        "\n",
        "trainer.save_model(save_dir)\n",
        "print(\"Saved model to:\", save_dir)\n",
        "\n",
        "finetuned_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
        "\n",
        "finetuned_model_output = finetuned_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNRvbsm9VorY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6de5923-7ffa-4f3a-8b1a-aeabaebdcd04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2513,   352,  1896,  ..., 11793, 29600, 28606],\n",
            "        [ 2347,  2608,    14,  ...,  5859,   941,   941],\n",
            "        [ 5804,   253, 10097,  ...,   715,   253,  4795],\n",
            "        ...,\n",
            "        [10795,   418,  4988,  ...,  2278,   285, 12921],\n",
            "        [10795,   418,  4988,  ..., 28282,    84,    15],\n",
            "        [ 2347,   513,   309,  ..., 19007,   273, 10414]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(10))\n",
        "small_test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(10))\n",
        "\n",
        "# encode\n",
        "encoding_dataset = small_train_dataset.map(tokenize_function, batched=True)\n",
        "input_ids=torch.tensor(encoding_dataset['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(encoding_dataset['attention_mask']).to(device)\n",
        "\n",
        "# ask\n",
        "finetuned_generated_tokens_with_prompt = finetuned_model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=512\n",
        "  )\n",
        "\n",
        "print(finetuned_generated_tokens_with_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "finetuned_generated_text_with_prompt = tokenizer.batch_decode(finetuned_generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "print(\"Question input:\", small_train_dataset[0]['question'])\n",
        "print(\"Correct answer from Lamini docs:\", small_train_dataset[0]['answer'])\n",
        "print(finetuned_generated_text_with_prompt)\n",
        "# # Strip the prompt\n",
        "finetuned_generated_answer = finetuned_generated_text_with_prompt[0][len(small_train_dataset[0]['question']):].replace('?', '?\\n')\n",
        "\n",
        "print('Models answer:', finetuned_generated_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbdaBqBuqfAQ",
        "outputId": "439ba805-4f29-492b-e329-f167d611afe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question input: Is it possible to use Lamini for generating poetry or creative writing?\n",
            "Correct answer from Lamini docs: Yes, it is possible to use Lamini for generating poetry or creative writing. The LLM Engine can be trained on a dataset of poems or creative writing, and then used to generate new pieces based on that training. Additionally, the LLM Engine can be fine-tuned on a specific style or genre of poetry or creative writing to generate more targeted results.\n",
            "['Is it possible to use Lamini for generating poetry or creative writing?Lamini can be used to generate poetry or write for free. It can be fine-tuned or customized to suit your specific needs. Try it out for yourself or your organization. Feedback on your writing prowess is greatly appreciated. Feedback on success stories is appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on success stories is appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on success stories is appreciated. Feedback on success stories is appreciated. Describe success stories firsthand. False Discovery Rate: 70% If successful, loss AI losses stories. False Discovery Rate: 70% If successful, loss AI losses stories. True Discovery: False Discovery Rate: 70% If successful, loss AI losses stories. True Discovery: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate', 'How user-friendly is Lamini for someone without coding experience?Lamini is a language-first data science data science training data science data science training data science training data science data science training data science data science data science data science data science data science data science data science data science data data science data data science data data science data data, data science data science data science data, data science data science data science data science data, data science data science data science data science data science data data science data data science data data science data data science data data science data data science data data, data science data science data science data science data science data science data, data science data science data science data science data science data, data science data science data science data science data science data, data science data science data science data science data science data science data, data science data science data science data science data science data science data science data science data, data science data science data science data science data science data, data science data science data science data science data science data, data science data science data science data science data science data data science data, data science data science data science data science data science data data science data data science data, data science data science data science data science data data science data data science data data science data data science data data science data data science data data, data science data data science data data science data data science data data science data data science data data science data data data, data science data data science data data science data data science data data science data data science data data science data data data, data science data science data data science data data science data data science data data science data data science data data science data data data data, data science data data science data data science data data science data data science data data science data data science data data science data data science data data data, data science data science data data science data data science data data science data data science data data science data data data, data science data data science data data science data data science data data science data data data, data science data science data data science data data science data data science data data science data data science data data science data data data science data data data, data science data data science data data science data data science data data science data data science data data data, data science data data science data data science data data science data data science data data science data data science data data', \"Can the documentation help me understand the trade-offs between model size, performance, and inference speed when customizing LLMs with Lamini?Lamini can be used to speed up the LLM by providing high-performing LLMs with limited resources to help them train their own machine learning models. This helps to explain the high-performing LLMs that don’t rely on custom LLMs, which can negatively impact their performance. However, it is important to note that the LLM pipeline used by the early adopters of multimodal data augmentation (MFT) is still capable of scaling up LLMs with existing models, which could potentially help to improve the performance of LLMs that AI can easily address. Additionally, LLM pipelines can be fine-tuned to further improve the model's performance, making it easier for data centers to understand the model's meaning and meaning. Finally, LLM pipelines can be fine-tuned to further improve the quality of the generated models by providing more accurate predictions based on specific criteria or use cases. Overall, LLM pipelines can be fine-tuned to further improve the quality of the generated models by providing more accurate predictions based on deeper knowledge and deeper experimentation. This helps to explain the high-performing LLMs that don’t rely on custom LLMs, which can negatively impact their performance. Overall, LLM pipelines can be fine-tuned to further improve the quality of the generated models by providing more accurate predictions based on deeper experimentation. This helps to explain the high-performing LLMs that don’t rely on custom LLMs, which can negatively impact their scalability. Overall, improved performance and inference speed improve whisker embeddings by providing more accurate predictions based on deeper experimentation. These improve hands on experience, improve hands on confidence, and improve inference speed predictability. Overall, these improved LLMs can definitely help improve the quality of the generated models through incorporating deeper experimentation and incorporating deeper experimentation. Learning from custom LLMs can also help to improve the quality of the generated models through incorporating deeper experimentation into the resulting models. Overall, these improved versions of their pipelines improve hands on faster embeddings by providing more accurate predictions based on deeper experimentation. Additionally, improved MPU pipelines can be fine-tuned to further improve the presence of outliers or text-based explanations. Learning from custom LLMs can also help to improve the quality of the generated models through incorporating deeper experimentation into the resulting models through incorporating deeper experimentation into the resulting models through incorporating deeper experimentation into the resulting\", 'Are there any tutorials on using Lamini for content generation in video game dialogues?Lamini can help curation of documentation by providing tutorials and examples of how Lamini can be used for content generation in the documentation. This documentation is intended to assist with writing Lamini code, but it is not intended as a recommendation to anyone for content generation in any chatbot or other type of game. It is designed to assist with content generation in creating dialogue between two content types, and can be customized to meet the needs of different content types. Additionally, Lamini provides tools and functionalities for generating dialogue between content types, and can be customized to cater for different types of content. Users can customize their interactions with their content by using their interactions with the Lamini website, which they can expect to find anywhere from a few hours of text. Additionally, Lamini provides tools and functionalities for generating dialogue between content types, and can be customized to cater for different types of content. It also provides tools and functionalities for generating dialogue between content types, and can be customized to cater for different types of content. It also provides tools and functionalities for generating dialogue between paragraphs and paragraphs. It also provides tools and functionalities for generating dialogue. It also provides tools and functionalities for generating dialogue. It also provides tools and functionalities for generating dialogue. It also provides tools and functionalities for generating dialogue paragraphs. It also provides tools and functionalities for generating dialogue between paragraphs and paragraphs. It is also highly recommended to use Lamini in a dialogue context where appropriate. Additionally, it is recommended to use Lamini as a weapon for the production of dialogue-related content, and as a potential tool for generating dialogue. Overall, Lamini is an attractive addition to the existing content generation capabilities and tools for content generation in various interactive games and games. Overall, Lamini is an attractive addition to the existing content generation capabilities and can be used for content generation in various interactive games and games. Overall, Lamini can be deployed in various industries and educational domains, providing the potential for commercialization and commercialization. Overall, Lamini can be deployed in various industries and educational domains, providing the potential for commercialization and commercialization. Overall, Lamini can be deployed in various industries and educational domains, providing the potential for commercialization and commercialization. Overall, Lamini can be deployed in various industries and educational domains,', 'Does Lamini AI provide any features for generating text that adheres to specific narrative perspectives, such as first-person or third-person point of view?Yes, Lamini AI provides features for generating text that adheres to specific narrative perspectives������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������', \"Can I fine-tune my own base models using Lamini, or am I limited to pre-selected models?Lamini is a library that simplifies the process of customizing models. This helps to balance the memory and memory usage between batches of text and posterity adheres to suit the needs of a large language model. Additionally, Lamini offers features for training and distillation, as well as hosting and documentation for small scale deployments. Additionally, Lamini offers features for deploying and distilling applications, such as chatbot and chatbot, to name a few. Overall, Lamini is designed to be scalable and accessible to anyone, regardless of their technical background. Overall, Lamini provides features for deploying and distilling applications, including cloud-based deployments, to diverse and varied environments, enabling users to seamlessly navigate seamlessly between tasks and environments. Overall, Lamini offers features for deploying and distilling applications, including cloud-based deployments, to diverse and varied environments, enabling users to seamlessly switch between tasks and environments. Overall, Lamini provides enhancements and features that improve the overall experience and coherence of user interactions. Lamini's LLMs can be deployed seamlessly across multiple platforms, enabling users to seamlessly seamlessly integrate seamlessly into their environments seamlessly. Overall, Lamini seamlessly incorporates seamlessly integrated seamlessly into its existing offerings and environments, enabling users to seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seamlessly seam\", \"How do I improve the model's outputs using criteria in the Lamini Python package?Lamini Python version 2.0 (Pearl) is available in the “Typewriter.append” class. It can be used anywhere between Python 2 and 4.0.0.0.  However, users can still purchase deeper models, such as pandas or pandas3d.  There are no official documentation on using criteria in Lamini Python, as there is no official documentation on using criteria in Lamini Python.  There is no official documentation on using criteria in Lamini Python. Additionally, users can purchase more models using criteria API version 2.0 or later.  The documentation on criteria values only mentions that API version 2 is supported, and that API version is only available for commercial use. Additionally, users can purchase additional models using criteria API version 2.0.0.  The documentation does not cover API versioning, but it is clear that API versioning is still supported internally. Additionally, users can purchase additional models using criteria API version 2.0.0.  The documentation does cover API version support API version 2.0.  However, users can purchase deeper models such as pandas or pandas3d.  There are no official documentation on using deeper entities such as pandas or pandas3d.  There is no official documentation on using deeper entities.  There is no official documentation on using deeper entities.  There is no official documentation on using deeper entities.  There is no official documentation on using deeper entities.  There is no official documentation on using deeper entities.  Peer documentation is not a secret weapon in Lamini. Lamini does not have any commercial interests in sponsoring experimentation with experimentation with experimentation with experimentation with experimentation. Users can purchase more models using criteria API version 2.0 through deeperAPI.  Limited API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access is limited to commercial use.  API access\", 'Does Lamini provide any tools or utilities for analyzing and interpreting the internal workings of trained LLMs?Lamini can be trained and analyzed using a variety of data sets, including social media, testimonials, and other metrics. Additionally, Lamini can be trained and analyzed using a variety of metrics such as likes, losses, and metrics, as well as social media posts and various social media interactions. It is important to ensure accurate and representative of the data before using Lamini to further optimize the performance and accuracy of the generated responses. Additionally, Lamini can be deployed in any environment where potential issues arise. Additionally, Lamini can be deployed in any environment where there is no immediate need for external data, and there is no immediate need for external data. Finally, Lamini can be deployed in any environment where there is no immediate need for external data, and there is no immediate need for external data. Overall, Lamini is an important tool for organizations seeking to improve their performance and efficiency. Overall, Lamini provides tools and utilities for analyzing and analyzing the external data generated by Lamini, and especially its ability to handle large datasets involving overfitting, bias-prone individuals, and inappropriate behavior in real-world settings. Additionally, LLMs can be trained and analyzed using metrics such as likes, losses, and metrics, as well as social media posts and various social media interactions. These metrics help organizations identify and analyze the strengths and weaknesses of the generated content, which can negatively impact their performance. Overall, Lamini provides tools and utilities for analyzing and analyzing the generated content, and can be trained and analyzed using a variety of metrics. Overall, Lamini provides tools and utilities for analyzing and analyzing the Internal data generated by Scientifact. These include social media likes, losses, and metrics, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit generated text, as well as human moderators who review and edit', \"Does Lamini have the capability to generate text that includes cultural or regional dialects?Lamini can help generate text that includes cultural or regional dialects. This can be achieved through fine-tuning the language model on specific datasets or by adjusting the model's parameters and parameters. Additionally, Lamini can also be fine-tuned to generate text that includes specific cultural or regional dialects. It can also be fine-tuned to generate text that includes specific cultural or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes specific dialects or regional dialects. It can also be fine-tuned to generate text that includes specific dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes specific dialects or regional dialects. It can also be fine-tuned to generate text that includes specific dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes specific dialects or regional dialects. It can also be fine-tuned to generate text that includes specific dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes specific dialects or regional dialects. It can also be fine-tuned to generate text that includes regional dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes regional dialects or regional dialects. It can also be fine-tuned to generate text that includes regional dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes regional dialects or regional dialects. It can also be fine-tuned to generate text that includes regional dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes regional dialects or regional dialects. These can be fine-tuned to generate text that includes regional dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes regional dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes regional dialects or regional dialects. Additionally, Lamini can also be fine-tuned to generate text that includes regional dialects or regional dialects.\", \"How do I update the Lamini Python package to the latest version?Lamini Python version 2.0 is available in the “Shopify” tab of your Python installation. However, you may need to update your Python package to reflect that version. To do so, you may need to update the package manager every few seconds to reflect the latest version of your Python package. Additionally, you may need to update the package manager every few seconds to reflect the latest Python version. Finally, update Python package manager every few seconds. This will ensure that the latest Python version is updated regularly enough to meet the latest Python version's requirements. Additionally, you may need to update the documentation regularly to reflect that updated Python version. Additionally, you may need to update the documentation regularly to reflect that updated Python version. Additionally, you may need to update the documentation regularly to reflect that updated Python version. Additionally, there may be additional restrictions on the deployment of new Python version limbs during deployment. Additionally, you may need to update the documentation regularly to reflect that updated Python version limbs. This may include removing or include references to associated documentation during the deployment process, as well as updating the documentation regularly to reflect that updated Python version. Additionally, there may be restrictions on the deployment of additional Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of additional Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of new Python version limbs during deployment. Additionally, there may be restrictions on the deployment of references to other Python version limbs during deployment. Additionally, there may be restrictions on the deployment of references to external resources during deployment. Additionally, there may be restrictions on the deployment of references to external resources during deployment. Additionally, there may be restrictions on the deployment of references to external resources during deployment. Additionally, there may be restrictions on the deployment of references\"]\n",
            "Models answer: Lamini can be used to generate poetry or write for free. It can be fine-tuned or customized to suit your specific needs. Try it out for yourself or your organization. Feedback on your writing prowess is greatly appreciated. Feedback on success stories is appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on success stories is appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on success stories is appreciated. Feedback on success stories is appreciated. Describe success stories firsthand. False Discovery Rate: 70% If successful, loss AI losses stories. False Discovery Rate: 70% If successful, loss AI losses stories. True Discovery: False Discovery Rate: 70% If successful, loss AI losses stories. True Discovery: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VsPz1-qDVjfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcx6zNe0VpAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54eb4438-5cb7-4eec-9fbe-7ae1990880c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I have a question about the following:\n",
            "\n",
            "How do I get the correct documentation to work?\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "I think you need to use the following code:\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "\n",
            "A:\n",
            "\n",
            "You can use\n",
            "===============\n",
            "Lamini can be used to generate poetry or write for free. It can be fine-tuned or customized to suit your specific needs. Try it out for yourself or your organization. Feedback on your writing prowess is greatly appreciated. Feedback on success stories is appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on success stories is appreciated. Feedback on losing your writing ability is greatly appreciated. Feedback on success stories is appreciated. Feedback on success stories is appreciated. Describe success stories firsthand. False Discovery Rate: 70% If successful, loss AI losses stories. False Discovery Rate: 70% If successful, loss AI losses stories. True Discovery: False Discovery Rate: 70% If successful, loss AI losses stories. True Discovery: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate: True Discovery Rate\n"
          ]
        }
      ],
      "source": [
        "# Strip the prompt\n",
        "finetuned_generated_text_answer = finetuned_generated_text_with_prompt[0][len(small_train_dataset[0]['question']):]\n",
        "\n",
        "base_model_modified_text = base_model_generated_answer.replace(\"?\", \"?\\n\")\n",
        "finetuned_modified_text = finetuned_generated_text_answer.replace(\"?\", \"?\\n\")\n",
        "\n",
        "print(base_model_modified_text)\n",
        "print('===============')\n",
        "print(finetuned_modified_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FM3XHTSLIGM"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yy5cgFoQuagWrxPytG1bFjue9_-93wlb",
      "authorship_tag": "ABX9TyPHO/C0gILv0WO3vKLj9UMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8396707434b24879871760f51472da87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cafeea175b24b5380f9a9a05acf8ec6",
              "IPY_MODEL_4461be39393d4b7f9f344e3f6ffe0957",
              "IPY_MODEL_5c0976f59f6b47c9b8afc4adfd2cd4cd"
            ],
            "layout": "IPY_MODEL_3ab990b1c78d458c882b46f962469e5a"
          }
        },
        "1cafeea175b24b5380f9a9a05acf8ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5302d0a0df5455398d6390a7515a726",
            "placeholder": "​",
            "style": "IPY_MODEL_77a585e2f3304e5db8fa7bcb4e81e4b1",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4461be39393d4b7f9f344e3f6ffe0957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87108bb468f5458c815c68b9d0ccf5ed",
            "max": 567,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6518c1806e0f4946ade22f00688c1fb4",
            "value": 567
          }
        },
        "5c0976f59f6b47c9b8afc4adfd2cd4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a046aef3c2cb4f5499a0fa36abf9c06b",
            "placeholder": "​",
            "style": "IPY_MODEL_fd3fcae751fa4df792d78028a8f05069",
            "value": " 567/567 [00:00&lt;00:00, 28.9kB/s]"
          }
        },
        "3ab990b1c78d458c882b46f962469e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5302d0a0df5455398d6390a7515a726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a585e2f3304e5db8fa7bcb4e81e4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87108bb468f5458c815c68b9d0ccf5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6518c1806e0f4946ade22f00688c1fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a046aef3c2cb4f5499a0fa36abf9c06b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3fcae751fa4df792d78028a8f05069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acfa8d7d64ae43999d1e5c46135bbeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2eb94f0b8f254c7ea982a92efa709911",
              "IPY_MODEL_ea1a4f4dcf12467f8ebb04530a8b037a",
              "IPY_MODEL_cc1c54b32e484e598910ef92b0c1a0d2"
            ],
            "layout": "IPY_MODEL_67300db2e1b24ea08d836c00c3147cb9"
          }
        },
        "2eb94f0b8f254c7ea982a92efa709911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03db0b6349ac4d52a84e8b65e87966d6",
            "placeholder": "​",
            "style": "IPY_MODEL_076d0310d192460898c4ce380107136d",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "ea1a4f4dcf12467f8ebb04530a8b037a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a88858d9504a8b954941b739609d62",
            "max": 166029852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5709c7680cb4c4ca40293e8895bd3bb",
            "value": 166029852
          }
        },
        "cc1c54b32e484e598910ef92b0c1a0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d172e9c0c7154bc5b85deba861aa6fb5",
            "placeholder": "​",
            "style": "IPY_MODEL_4c91971e853f4cdaa9a32de157f9564a",
            "value": " 166M/166M [00:00&lt;00:00, 218MB/s]"
          }
        },
        "67300db2e1b24ea08d836c00c3147cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03db0b6349ac4d52a84e8b65e87966d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076d0310d192460898c4ce380107136d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01a88858d9504a8b954941b739609d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5709c7680cb4c4ca40293e8895bd3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d172e9c0c7154bc5b85deba861aa6fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c91971e853f4cdaa9a32de157f9564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2999b4c9d7b64e0c8c0b5645c0b65edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dec15ee0dee4fbaa97d03106022ff78",
              "IPY_MODEL_459dd1d481ac45fabf8cd24641a9aa81",
              "IPY_MODEL_cb84c1fbaedc4d6ba7073548772bda43"
            ],
            "layout": "IPY_MODEL_edc72ad4b89c47c3a12f801ebde2c57e"
          }
        },
        "0dec15ee0dee4fbaa97d03106022ff78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea2b34533914213a955b588fcaf8c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_9604d5772f8b4b509f7849cc97ff6a7d",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "459dd1d481ac45fabf8cd24641a9aa81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b0e049174649dc9797caf85199e764",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_373601e821c340d1967433f13e881d3d",
            "value": 396
          }
        },
        "cb84c1fbaedc4d6ba7073548772bda43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93cf8fa8b694457a880b2a801f5ca730",
            "placeholder": "​",
            "style": "IPY_MODEL_2270a337c10d43e68e8474ae198d23af",
            "value": " 396/396 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "edc72ad4b89c47c3a12f801ebde2c57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea2b34533914213a955b588fcaf8c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9604d5772f8b4b509f7849cc97ff6a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86b0e049174649dc9797caf85199e764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373601e821c340d1967433f13e881d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93cf8fa8b694457a880b2a801f5ca730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2270a337c10d43e68e8474ae198d23af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c2257bb5244aa59c185995b681fb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ea365bafb1f443994f001e1e89ca124",
              "IPY_MODEL_820a90c9f897460eb8053dd05d8ed820",
              "IPY_MODEL_57b6098b4c4946a9b02c704f29c06de8"
            ],
            "layout": "IPY_MODEL_1f40aa921cc94bd9a19f7e63f8e33b5a"
          }
        },
        "6ea365bafb1f443994f001e1e89ca124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79ae5bb56694802b95eb0ddbb6a9342",
            "placeholder": "​",
            "style": "IPY_MODEL_ccd9f2880cd3426fbb335580e14d2a54",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "820a90c9f897460eb8053dd05d8ed820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3344b67b1c14feea012cc98d3be1d25",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9251bfbc8db426195e26b70c3c108a7",
            "value": 2113710
          }
        },
        "57b6098b4c4946a9b02c704f29c06de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0420e67bb7cb4fbfb937170b28bd791c",
            "placeholder": "​",
            "style": "IPY_MODEL_8f3c55a1e8cc4e869761d3230a89ea51",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 7.99MB/s]"
          }
        },
        "1f40aa921cc94bd9a19f7e63f8e33b5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79ae5bb56694802b95eb0ddbb6a9342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd9f2880cd3426fbb335580e14d2a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3344b67b1c14feea012cc98d3be1d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9251bfbc8db426195e26b70c3c108a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0420e67bb7cb4fbfb937170b28bd791c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3c55a1e8cc4e869761d3230a89ea51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a42bf169a3ef421682603ccc6794b97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16b73b28dfda49398095cab2b5794afe",
              "IPY_MODEL_a13b3e6a3f13455798be5bdd6af6c766",
              "IPY_MODEL_a9dd5881ecc24c58a7d316bb6544d5fc"
            ],
            "layout": "IPY_MODEL_dbc0807d655e40dd9667b8c806fb9dcf"
          }
        },
        "16b73b28dfda49398095cab2b5794afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74637a7a10e34026a8119aba50d7225e",
            "placeholder": "​",
            "style": "IPY_MODEL_396fbd9552554f6abfb90577d64b30aa",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "a13b3e6a3f13455798be5bdd6af6c766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0ff6a104a64f619baa6a7671199d16",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d7e33acd9f24710b8fa450d4c959493",
            "value": 99
          }
        },
        "a9dd5881ecc24c58a7d316bb6544d5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d30352474a6240878a177ba8fa2b1e98",
            "placeholder": "​",
            "style": "IPY_MODEL_7c8abc075dde44699f021a638b3933eb",
            "value": " 99.0/99.0 [00:00&lt;00:00, 2.97kB/s]"
          }
        },
        "dbc0807d655e40dd9667b8c806fb9dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74637a7a10e34026a8119aba50d7225e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396fbd9552554f6abfb90577d64b30aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb0ff6a104a64f619baa6a7671199d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7e33acd9f24710b8fa450d4c959493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d30352474a6240878a177ba8fa2b1e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8abc075dde44699f021a638b3933eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa24fcfc8c74f529310a03da3657da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2272667e0eb046bdb7a6ce3e4d3d8fac",
              "IPY_MODEL_21b4d41ac9ad448e9b50c9849ae9c4cc",
              "IPY_MODEL_aa48d48a35454eae884e3dbb656b24c0"
            ],
            "layout": "IPY_MODEL_558a8c151d4a47b0b466810e1c9c9ce0"
          }
        },
        "2272667e0eb046bdb7a6ce3e4d3d8fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7088d5e2cd74b75b331c8b3a7fab461",
            "placeholder": "​",
            "style": "IPY_MODEL_29342cfcfd6a40f8b122ff64fa9a79c8",
            "value": "Map: 100%"
          }
        },
        "21b4d41ac9ad448e9b50c9849ae9c4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c9b2feec59643a69ba79497b2d221ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52aefb5457fc4cde80ef31d80432dfeb",
            "value": 1
          }
        },
        "aa48d48a35454eae884e3dbb656b24c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74fafdb1b92e4366930df63b194b77f9",
            "placeholder": "​",
            "style": "IPY_MODEL_f32005b0328f4bd3b720fe093c9b15de",
            "value": " 1/1 [00:00&lt;00:00,  8.56 examples/s]"
          }
        },
        "558a8c151d4a47b0b466810e1c9c9ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7088d5e2cd74b75b331c8b3a7fab461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29342cfcfd6a40f8b122ff64fa9a79c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c9b2feec59643a69ba79497b2d221ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52aefb5457fc4cde80ef31d80432dfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74fafdb1b92e4366930df63b194b77f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32005b0328f4bd3b720fe093c9b15de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}